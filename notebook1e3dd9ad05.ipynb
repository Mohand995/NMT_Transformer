{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n!unzip -q spa-eng.zip","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-21T17:42:47.010259Z","iopub.execute_input":"2023-04-21T17:42:47.010949Z","iopub.status.idle":"2023-04-21T17:42:49.428002Z","shell.execute_reply.started":"2023-04-21T17:42:47.010908Z","shell.execute_reply":"2023-04-21T17:42:49.426345Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2023-04-21 17:42:47--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 142.250.107.128, 74.125.20.128, 108.177.98.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.250.107.128|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2638744 (2.5M) [application/zip]\nSaving to: ‘spa-eng.zip’\n\nspa-eng.zip         100%[===================>]   2.52M  --.-KB/s    in 0.02s   \n\n2023-04-21 17:42:48 (159 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import random \nimport os \nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom  tensorflow import keras\nimport string \nimport re","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:43:15.155926Z","iopub.execute_input":"2023-04-21T17:43:15.156341Z","iopub.status.idle":"2023-04-21T17:43:22.516648Z","shell.execute_reply.started":"2023-04-21T17:43:15.156300Z","shell.execute_reply":"2023-04-21T17:43:22.514511Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"file='/kaggle/working/spa-eng/spa.txt'\ndata_pairs=[]\nwith open(file) as f:\n  lines=f.read().split(\"\\n\")[:-1]\n  for l in lines:\n    eng,spn=l.split(\"\\t\")\n    spn='[start] '+spn+' [end]'\n    data_pairs.append((eng,spn))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:45:11.877061Z","iopub.execute_input":"2023-04-21T17:45:11.877778Z","iopub.status.idle":"2023-04-21T17:45:12.058786Z","shell.execute_reply.started":"2023-04-21T17:45:11.877738Z","shell.execute_reply":"2023-04-21T17:45:12.057709Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"random.choice(data_pairs)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:45:26.348338Z","iopub.execute_input":"2023-04-21T17:45:26.348934Z","iopub.status.idle":"2023-04-21T17:45:26.356755Z","shell.execute_reply.started":"2023-04-21T17:45:26.348895Z","shell.execute_reply":"2023-04-21T17:45:26.355678Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('Tom was waiting for Mary.', '[start] Tom estaba esperando a Mary. [end]')"},"metadata":{}}]},{"cell_type":"code","source":"num_val_samples=int(len(data_pairs)*0.15)\nnum_train_examples=int(len(data_pairs)-2*num_val_samples)\nrandom.shuffle(data_pairs)\ntrain_data=data_pairs[:num_train_examples]\nval_data=data_pairs[num_train_examples:num_train_examples+num_val_samples]\ntest_data=data_pairs[num_train_examples+num_val_samples:]","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:45:44.477378Z","iopub.execute_input":"2023-04-21T17:45:44.477850Z","iopub.status.idle":"2023-04-21T17:45:44.599046Z","shell.execute_reply.started":"2023-04-21T17:45:44.477812Z","shell.execute_reply":"2023-04-21T17:45:44.597996Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(len(train_data))\nprint(\"-------------------\")\nprint(len(val_data))\nprint(\"-------------------\")\nprint(len(test_data))\nprint(\"-------------------\")","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:46:12.463614Z","iopub.execute_input":"2023-04-21T17:46:12.464460Z","iopub.status.idle":"2023-04-21T17:46:12.470549Z","shell.execute_reply.started":"2023-04-21T17:46:12.464417Z","shell.execute_reply":"2023-04-21T17:46:12.469281Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"83276\n-------------------\n17844\n-------------------\n17844\n-------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"uneeded_chars=string.punctuation+\"¿\"\nuneeded_chars.replace(\"[\",\"\")\nuneeded_chars.replace(\"]\",\"\")\n\ndef clear_text(text):\n  lower_cased=tf.strings.lower(text)\n  return tf.strings.regex_replace(lower_cased,f\"[{re.escape(uneeded_chars)}]\",\"\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:46:32.309962Z","iopub.execute_input":"2023-04-21T17:46:32.310458Z","iopub.status.idle":"2023-04-21T17:46:32.317044Z","shell.execute_reply.started":"2023-04-21T17:46:32.310420Z","shell.execute_reply":"2023-04-21T17:46:32.316023Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"vocab_size=15000\nmax_length=20\n\nsource_vectorization=layers.TextVectorization(\n    max_tokens=vocab_size,output_mode='int',output_sequence_length=max_length\n)\n\ntarget_vectorization=layers.TextVectorization(\n    max_tokens=vocab_size,output_mode='int',output_sequence_length=max_length+1,standardize=clear_text\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:46:45.712244Z","iopub.execute_input":"2023-04-21T17:46:45.713160Z","iopub.status.idle":"2023-04-21T17:46:48.322267Z","shell.execute_reply.started":"2023-04-21T17:46:45.713104Z","shell.execute_reply":"2023-04-21T17:46:48.321251Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"eng_train= [p[0]for p in train_data]\nspn_train= [p[1]for p in train_data]\n\nsource_vectorization.adapt(eng_train)\ntarget_vectorization.adapt(spn_train)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:46:59.555943Z","iopub.execute_input":"2023-04-21T17:46:59.556429Z","iopub.status.idle":"2023-04-21T17:47:10.925507Z","shell.execute_reply.started":"2023-04-21T17:46:59.556389Z","shell.execute_reply":"2023-04-21T17:47:10.924048Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def format_dataset(eng,spa):\n  eng=source_vectorization(eng)\n  spa=target_vectorization(spa)\n  return (\n      {\n          'eng':eng,\n          'spa':spa[:,:-1]\n        \n      }, spa[:,1:])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:47:14.700644Z","iopub.execute_input":"2023-04-21T17:47:14.701021Z","iopub.status.idle":"2023-04-21T17:47:14.707400Z","shell.execute_reply.started":"2023-04-21T17:47:14.700988Z","shell.execute_reply":"2023-04-21T17:47:14.706053Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"batch_size=64\nAutotune=tf.data.experimental.AUTOTUNE\n\ndef load_data(pairs):\n  eng,spa=zip(*pairs)\n  eng=list(eng)\n  spa=list(spa)\n  train_tensor=tf.data.Dataset.from_tensor_slices(\n      (eng,spa)\n  )\n  train_tensor=train_tensor.batch(batch_size)\n  train_tensor=train_tensor.map(format_dataset,num_parallel_calls=Autotune)\n  return train_tensor.shuffle(2048).prefetch(16).cache()\n\ntrain_dataset=load_data(train_data)\nval_dataset=load_data(val_data)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:45:18.763766Z","iopub.execute_input":"2023-04-21T18:45:18.764613Z","iopub.status.idle":"2023-04-21T18:45:19.581259Z","shell.execute_reply.started":"2023-04-21T18:45:18.764568Z","shell.execute_reply":"2023-04-21T18:45:19.580230Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"for inputs, targets in train_dataset.take(1):\n    print(f\"inputs['english'].shape: {inputs['eng'].shape}\")\n    print(f\"inputs['spanish'].shape: {inputs['spa'].shape}\")\n    print(f\"targets.shape: {targets.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:47:47.478752Z","iopub.execute_input":"2023-04-21T17:47:47.479156Z","iopub.status.idle":"2023-04-21T17:47:48.099654Z","shell.execute_reply.started":"2023-04-21T17:47:47.479106Z","shell.execute_reply":"2023-04-21T17:47:48.098535Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"inputs['english'].shape: (64, 20)\ninputs['spanish'].shape: (64, 20)\ntargets.shape: (64, 20)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**# 1-Seq2Seq Model**","metadata":{}},{"cell_type":"code","source":"embedding_dim=256\nlatent_dim=1024\n\n\nsource_input=keras.Input(shape=(None,),name='eng',dtype='int64')\nx=layers.Embedding(vocab_size,embedding_dim,mask_zero=True)(source_input)\nencoded_source=layers.Bidirectional(layers.GRU(latent_dim),merge_mode='sum')(x)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:48:43.274034Z","iopub.execute_input":"2023-04-21T17:48:43.274753Z","iopub.status.idle":"2023-04-21T17:48:46.546397Z","shell.execute_reply.started":"2023-04-21T17:48:43.274712Z","shell.execute_reply":"2023-04-21T17:48:46.545363Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"target_input=keras.Input(shape=(None,),name='spa',dtype='int64')\nx=layers.Embedding(vocab_size,embedding_dim,mask_zero=True)(target_input)\ndecoder_gru = layers.GRU(latent_dim,return_sequences=True)\nx = decoder_gru(x, initial_state=encoded_source)\nx = layers.Dropout(0.5)(x)\ntarget_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)\nseq2seq_rnn = keras.Model([source_input, target_input], target_next_step)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:48:56.871941Z","iopub.execute_input":"2023-04-21T17:48:56.872452Z","iopub.status.idle":"2023-04-21T17:48:58.377462Z","shell.execute_reply.started":"2023-04-21T17:48:56.872411Z","shell.execute_reply":"2023-04-21T17:48:58.376462Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"seq2seq_rnn.compile(\n    optimizer=\"rmsprop\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"])\nseq2seq_rnn.fit(train_dataset ,epochs=15, validation_data=val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T17:49:19.243345Z","iopub.execute_input":"2023-04-21T17:49:19.243717Z","iopub.status.idle":"2023-04-21T18:17:20.518942Z","shell.execute_reply.started":"2023-04-21T17:49:19.243684Z","shell.execute_reply":"2023-04-21T18:17:20.517957Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/15\n1302/1302 [==============================] - 137s 92ms/step - loss: 4.6828 - accuracy: 0.3183 - val_loss: 3.9057 - val_accuracy: 0.3860\nEpoch 2/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 3.7266 - accuracy: 0.4140 - val_loss: 3.2529 - val_accuracy: 0.4663\nEpoch 3/15\n1302/1302 [==============================] - 103s 79ms/step - loss: 3.2185 - accuracy: 0.4718 - val_loss: 2.8763 - val_accuracy: 0.5158\nEpoch 4/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 2.8631 - accuracy: 0.5123 - val_loss: 2.6261 - val_accuracy: 0.5502\nEpoch 5/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 2.5894 - accuracy: 0.5448 - val_loss: 2.4635 - val_accuracy: 0.5729\nEpoch 6/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 2.3686 - accuracy: 0.5725 - val_loss: 2.3462 - val_accuracy: 0.5911\nEpoch 7/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 2.1862 - accuracy: 0.5959 - val_loss: 2.2354 - val_accuracy: 0.6080\nEpoch 8/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 2.0290 - accuracy: 0.6165 - val_loss: 2.1579 - val_accuracy: 0.6199\nEpoch 9/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 1.8931 - accuracy: 0.6350 - val_loss: 2.1042 - val_accuracy: 0.6295\nEpoch 10/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 1.7737 - accuracy: 0.6515 - val_loss: 2.0667 - val_accuracy: 0.6349\nEpoch 11/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 1.6701 - accuracy: 0.6666 - val_loss: 2.0239 - val_accuracy: 0.6420\nEpoch 12/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 1.5727 - accuracy: 0.6807 - val_loss: 2.0016 - val_accuracy: 0.6465\nEpoch 13/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 1.4948 - accuracy: 0.6914 - val_loss: 1.9762 - val_accuracy: 0.6510\nEpoch 14/15\n1302/1302 [==============================] - 104s 80ms/step - loss: 1.4235 - accuracy: 0.7021 - val_loss: 1.9563 - val_accuracy: 0.6550\nEpoch 15/15\n1302/1302 [==============================] - 105s 81ms/step - loss: 1.3604 - accuracy: 0.7116 - val_loss: 1.9399 - val_accuracy: 0.6581\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7207384c4850>"},"metadata":{}}]},{"cell_type":"code","source":"spa_vocab = target_vectorization.get_vocabulary()\nspanish_lookup=dict()\nfor i,tok in enumerate(spa_vocab):\n  spanish_lookup[i]=tok","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:17:33.691352Z","iopub.execute_input":"2023-04-21T18:17:33.692080Z","iopub.status.idle":"2023-04-21T18:17:33.734324Z","shell.execute_reply.started":"2023-04-21T18:17:33.692041Z","shell.execute_reply":"2023-04-21T18:17:33.733287Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def decode_sequence(sentence):\n  input_encoded=source_vectorization([sentence])\n  max_length=20\n  decoded_sentence='start'\n  for i in range(max_length):\n    target_encoded=target_vectorization([decoded_sentence])\n    predicted_probabilities=seq2seq_rnn.predict([input_encoded,target_encoded])\n    predicted_token=np.argmax(predicted_probabilities[0,i,:])\n    predicted_token=spanish_lookup[predicted_token]\n    if predicted_token=='end':\n      break\n    decoded_sentence += \" \" + predicted_token\n\n  return decoded_sentence[5:]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:17:37.782680Z","iopub.execute_input":"2023-04-21T18:17:37.783385Z","iopub.status.idle":"2023-04-21T18:17:37.791422Z","shell.execute_reply.started":"2023-04-21T18:17:37.783338Z","shell.execute_reply":"2023-04-21T18:17:37.789803Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"txt='we want to buy a car'\ndecode_sequence(txt)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:17:38.135924Z","iopub.execute_input":"2023-04-21T18:17:38.136669Z","iopub.status.idle":"2023-04-21T18:17:42.251711Z","shell.execute_reply.started":"2023-04-21T18:17:38.136626Z","shell.execute_reply":"2023-04-21T18:17:42.250578Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 3s 3s/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 24ms/step\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"' queremos comprar un coche'"},"metadata":{}}]},{"cell_type":"code","source":"class TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim)\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(dense_dim, activation=\"relu\"),\n             layers.Dense(embed_dim),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            mask = mask[:, tf.newaxis, :]\n        attention_output = self.attention(\n            inputs, inputs, attention_mask=mask)\n        proj_input = self.layernorm_1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm_2(proj_input + proj_output)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"embed_dim\": self.embed_dim,\n            \"num_heads\": self.num_heads,\n            \"dense_dim\": self.dense_dim,\n        })\n        return config\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:57:24.852353Z","iopub.execute_input":"2023-04-21T18:57:24.853105Z","iopub.status.idle":"2023-04-21T18:57:24.865462Z","shell.execute_reply.started":"2023-04-21T18:57:24.853063Z","shell.execute_reply":"2023-04-21T18:57:24.864273Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention_1 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim)\n        self.attention_2 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim)\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(dense_dim, activation=\"relu\"),\n             layers.Dense(embed_dim),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.layernorm_3 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"embed_dim\": self.embed_dim,\n            \"num_heads\": self.num_heads,\n            \"dense_dim\": self.dense_dim,\n        })\n        return config\n\n    def get_causal_attention_mask(self, inputs):\n        input_shape = tf.shape(inputs)\n        batch_size, sequence_length = input_shape[0], input_shape[1]\n        i = tf.range(sequence_length)[:, tf.newaxis]\n        j = tf.range(sequence_length)\n        mask = tf.cast(i >= j, dtype=\"int32\")\n        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n        mult = tf.concat(\n            [tf.expand_dims(batch_size, -1),\n             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n        return tf.tile(mask, mult)\n\n    def call(self, inputs, encoder_outputs, mask=None):\n        causal_mask = self.get_causal_attention_mask(inputs)\n        if mask is not None:\n            padding_mask = tf.cast(\n                mask[:, tf.newaxis, :], dtype=\"int32\")\n            padding_mask = tf.minimum(padding_mask, causal_mask)\n        else:\n            padding_mask = mask\n        attention_output_1 = self.attention_1(\n            query=inputs,\n            value=inputs,\n            key=inputs,\n            attention_mask=causal_mask)\n        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n        attention_output_2 = self.attention_2(\n            query=attention_output_1,\n            value=encoder_outputs,\n            key=encoder_outputs,\n            attention_mask=padding_mask,\n        )\n        attention_output_2 = self.layernorm_2(\n            attention_output_1 + attention_output_2)\n        proj_output = self.dense_proj(attention_output_2)\n        return self.layernorm_3(attention_output_2 + proj_output)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:57:25.243378Z","iopub.execute_input":"2023-04-21T18:57:25.244105Z","iopub.status.idle":"2023-04-21T18:57:25.257863Z","shell.execute_reply.started":"2023-04-21T18:57:25.244062Z","shell.execute_reply":"2023-04-21T18:57:25.256426Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"class PositionalEmbedding(layers.Layer):\n    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n        super().__init__(**kwargs)\n        self.token_embeddings = layers.Embedding(\n            input_dim=input_dim, output_dim=output_dim)\n        self.position_embeddings = layers.Embedding(\n            input_dim=sequence_length, output_dim=output_dim)\n        self.sequence_length = sequence_length\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n        return tf.math.not_equal(inputs, 0)\n\n    def get_config(self):\n        config = super(PositionalEmbedding, self).get_config()\n        config.update({\n            \"output_dim\": self.output_dim,\n            \"sequence_length\": self.sequence_length,\n            \"input_dim\": self.input_dim,\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:57:25.783288Z","iopub.execute_input":"2023-04-21T18:57:25.784238Z","iopub.status.idle":"2023-04-21T18:57:25.793776Z","shell.execute_reply.started":"2023-04-21T18:57:25.784160Z","shell.execute_reply":"2023-04-21T18:57:25.792541Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"embed_dim = 256\ndense_dim = 2048\nnum_heads = 8\nsequence_length=20\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"eng\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\nencoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n\ndecoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spa\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\nx = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\nx = layers.Dropout(0.5)(x)\ndecoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\ntransformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:57:26.917710Z","iopub.execute_input":"2023-04-21T18:57:26.918627Z","iopub.status.idle":"2023-04-21T18:57:27.618391Z","shell.execute_reply.started":"2023-04-21T18:57:26.918575Z","shell.execute_reply":"2023-04-21T18:57:27.617371Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"transformer.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:57:29.335327Z","iopub.execute_input":"2023-04-21T18:57:29.336030Z","iopub.status.idle":"2023-04-21T18:57:29.367483Z","shell.execute_reply.started":"2023-04-21T18:57:29.335993Z","shell.execute_reply":"2023-04-21T18:57:29.366657Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Model: \"model_5\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n eng (InputLayer)               [(None, None)]       0           []                               \n                                                                                                  \n spa (InputLayer)               [(None, None)]       0           []                               \n                                                                                                  \n positional_embedding_20 (Posit  (None, None, 256)   3845120     ['eng[0][0]']                    \n ionalEmbedding)                                                                                  \n                                                                                                  \n positional_embedding_21 (Posit  (None, None, 256)   3845120     ['spa[0][0]']                    \n ionalEmbedding)                                                                                  \n                                                                                                  \n transformer_encoder_10 (Transf  (None, None, 256)   3155456     ['positional_embedding_20[0][0]']\n ormerEncoder)                                                                                    \n                                                                                                  \n transformer_decoder_9 (Transfo  (None, None, 256)   5259520     ['positional_embedding_21[0][0]',\n rmerDecoder)                                                     'transformer_encoder_10[0][0]'] \n                                                                                                  \n dropout_5 (Dropout)            (None, None, 256)    0           ['transformer_decoder_9[0][0]']  \n                                                                                                  \n dense_45 (Dense)               (None, None, 15000)  3855000     ['dropout_5[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 19,960,216\nTrainable params: 19,960,216\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"transformer.compile(\n    optimizer=\"rmsprop\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"])\ntransformer.fit(train_dataset, epochs=15, validation_data=val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T18:57:29.777134Z","iopub.execute_input":"2023-04-21T18:57:29.778519Z","iopub.status.idle":"2023-04-21T19:19:37.874300Z","shell.execute_reply.started":"2023-04-21T18:57:29.778461Z","shell.execute_reply":"2023-04-21T19:19:37.873270Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Epoch 1/15\n1302/1302 [==============================] - 101s 72ms/step - loss: 3.7943 - accuracy: 0.4396 - val_loss: 2.8970 - val_accuracy: 0.5359\nEpoch 2/15\n1302/1302 [==============================] - 85s 65ms/step - loss: 2.8505 - accuracy: 0.5504 - val_loss: 2.5610 - val_accuracy: 0.5848\nEpoch 3/15\n1302/1302 [==============================] - 85s 65ms/step - loss: 2.5526 - accuracy: 0.5940 - val_loss: 2.3876 - val_accuracy: 0.6162\nEpoch 4/15\n1302/1302 [==============================] - 85s 65ms/step - loss: 2.3887 - accuracy: 0.6205 - val_loss: 2.3817 - val_accuracy: 0.6199\nEpoch 5/15\n1302/1302 [==============================] - 84s 65ms/step - loss: 2.2848 - accuracy: 0.6387 - val_loss: 2.3152 - val_accuracy: 0.6329\nEpoch 6/15\n1302/1302 [==============================] - 84s 65ms/step - loss: 2.2122 - accuracy: 0.6522 - val_loss: 2.3130 - val_accuracy: 0.6364\nEpoch 7/15\n1302/1302 [==============================] - 84s 65ms/step - loss: 2.1528 - accuracy: 0.6639 - val_loss: 2.3095 - val_accuracy: 0.6410\nEpoch 8/15\n1302/1302 [==============================] - 84s 65ms/step - loss: 2.0932 - accuracy: 0.6754 - val_loss: 2.2726 - val_accuracy: 0.6485\nEpoch 9/15\n1302/1302 [==============================] - 84s 65ms/step - loss: 2.0419 - accuracy: 0.6855 - val_loss: 2.2567 - val_accuracy: 0.6557\nEpoch 10/15\n1302/1302 [==============================] - 85s 65ms/step - loss: 1.9968 - accuracy: 0.6937 - val_loss: 2.2704 - val_accuracy: 0.6573\nEpoch 11/15\n1302/1302 [==============================] - 84s 65ms/step - loss: 1.9535 - accuracy: 0.7020 - val_loss: 2.2525 - val_accuracy: 0.6588\nEpoch 12/15\n1302/1302 [==============================] - 84s 65ms/step - loss: 1.9247 - accuracy: 0.7072 - val_loss: 2.2532 - val_accuracy: 0.6624\nEpoch 13/15\n1302/1302 [==============================] - 84s 65ms/step - loss: 1.8970 - accuracy: 0.7123 - val_loss: 2.2777 - val_accuracy: 0.6646\nEpoch 14/15\n1302/1302 [==============================] - 84s 65ms/step - loss: 1.8722 - accuracy: 0.7170 - val_loss: 2.2914 - val_accuracy: 0.6600\nEpoch 15/15\n1302/1302 [==============================] - 85s 65ms/step - loss: 1.8514 - accuracy: 0.7210 - val_loss: 2.2627 - val_accuracy: 0.6683\n","output_type":"stream"},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7202c0fb4610>"},"metadata":{}}]},{"cell_type":"code","source":"def decode_sequence_2(sentence):\n  input_encoded=source_vectorization([sentence])\n  max_length=20\n  decoded_sentence='start'\n  for i in range(max_length):\n    target_encoded=target_vectorization([decoded_sentence])\n    predicted_probabilities=transformer.predict([input_encoded,target_encoded])\n    predicted_token=np.argmax(predicted_probabilities[0,i,:])\n    predicted_token=spanish_lookup[predicted_token]\n    if predicted_token=='end':\n      break\n    decoded_sentence += \" \" + predicted_token\n\n  return decoded_sentence[5:]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T19:20:29.365842Z","iopub.execute_input":"2023-04-21T19:20:29.366340Z","iopub.status.idle":"2023-04-21T19:20:29.375434Z","shell.execute_reply.started":"2023-04-21T19:20:29.366290Z","shell.execute_reply":"2023-04-21T19:20:29.374327Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}